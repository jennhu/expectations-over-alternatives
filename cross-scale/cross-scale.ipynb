{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6ff938-c167-4d9a-aa2f-1978b16785e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from scipy import stats\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.notebook import tqdm\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3336fe79-ac01-4e3e-a0af-72e3e50a3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global plotting constants.\n",
    "sns.set(style=\"white\", font_scale=1.5, font=\"Liberation Sans\")\n",
    "SURPRISAL_COLOR = \"steelblue\"\n",
    "MARKERS = [\"o\", \"v\", \"s\", \"d\"] # use markers to differentiate between datasets\n",
    "\n",
    "DATASET_NAMES = {\n",
    "    \"rx22\": \"Ronai & Xiang (2022)\",\n",
    "    \"pvt21\": \"Pankratz & van Tiel (2021)\",\n",
    "    \"g18\": \"Gotzner et al. (2018)\",\n",
    "    \"vt16\": \"van Tiel et al. (2016)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593445c5-80b7-4b88-8ff0-a15031edfc37",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e9a03-1f8b-4906-bf30-433bd3b47056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(file, fig_dir=\"figures\"):\n",
    "    path = f\"{fig_dir}/{file}\"\n",
    "    plt.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"Rendered figure to {path}\")\n",
    "\n",
    "def regplt(df, x, y, label_name=\"Weaker\", annot=True, **kwargs):\n",
    "    pearsonr, pearsonp = stats.pearsonr(df[x], df[y])\n",
    "    print(f\"Pearson r={pearsonr}, p={pearsonp}\")\n",
    "    spearmanr, spearmanp = stats.spearmanr(df[x], df[y])\n",
    "    print(f\"Spearman r={spearmanr}, p={spearmanp}\")\n",
    "\n",
    "    # Plot\n",
    "    ax = sns.regplot(data=df, x=x, y=y, **kwargs)\n",
    "    plt.gcf().set_size_inches(8,6)\n",
    "    if annot:\n",
    "        for i, row in df.iterrows():\n",
    "            ax.text(row[x], row[y], row[label_name], size=\"xx-small\")\n",
    "    return ax, pearsonr, pearsonp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c3bb00-d862-4b08-9c05-2f0f92e1f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a bunch of model outputs in TSV SyntaxGym format.\n",
    "def read_results(result_dir):\n",
    "    files = sorted([f for f in listdir(result_dir) if f.endswith(\"gpt2.tsv\")])\n",
    "    dfs = []\n",
    "    sentence_dfs = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            _df = pd.read_csv(result_dir + \"/\" + f, sep=\"\\t\")\n",
    "            weak, strong, model = f[:-4].split(\"_\")\n",
    "            scale_id = weak + \"/\" + strong\n",
    "            _df[\"scale_id\"] = scale_id\n",
    "            _df[\"model\"] = model\n",
    "            dfs.append(_df)\n",
    "            \n",
    "            g = _df.fillna(\"\").groupby(\"item_number\").agg({'content': \" \".join}).reset_index()\n",
    "            g[\"scale_id\"] = scale_id\n",
    "            g[\"content\"] = g.content.str.replace(\" .\", \".\", regex=False).replace(\"\\s+,\", \",\", regex=True)\n",
    "            sentence_dfs.append(g)\n",
    "        except:\n",
    "            print(f\"Skipping {f}\")\n",
    "    df = pd.concat(dfs)\n",
    "    sentence_df = pd.concat(sentence_dfs)\n",
    "    return df, sentence_df\n",
    "\n",
    "def get_strong_surprisal_df(surprisal_df, region_numbers=[5]):\n",
    "    print(\"Only considering surprisal at the following regions:\", region_numbers)\n",
    "    \n",
    "    # Get subset of surprisals that correspond to specified region numbers.\n",
    "    strong_surprisal_df = surprisal_df[surprisal_df.region_number.isin(region_numbers)].fillna(\"\")\n",
    "    \n",
    "    # Sum surprisal and concatenate string content over regions of interest.\n",
    "    strong_surprisal_df = strong_surprisal_df.groupby(\n",
    "        [\"scale_id\", \"item_number\"]\n",
    "    ).agg(\n",
    "        {\"content\": \" \".join, \"metric_value\": np.sum}\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Deal with edge case (removing extra space before EOS period).\n",
    "    strong_surprisal_df[\"content\"] = strong_surprisal_df.content.str.replace(\" .\", \".\", regex=False)\n",
    "    \n",
    "    # Add unique ID for each item.\n",
    "    strong_surprisal_df[\"unique_id\"] = strong_surprisal_df.scale_id + \"_\" + strong_surprisal_df.item_number.astype(str)\n",
    "    \n",
    "    return strong_surprisal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be642e9-4af1-4600-9eff-29e18169f1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_model_outputs(result_dir, stimuli_file, model=\"gpt2\", template=None):\n",
    "    # Read model outputs and only consider surprisal at target region.\n",
    "    df, sentence_df = read_results(result_dir)\n",
    "    strong_surp = get_strong_surprisal_df(df).reset_index()\n",
    "    \n",
    "    # Read original data file with stimuli and human empirical results.\n",
    "    print(f\"Reading stimuli from {stimuli_file}\")\n",
    "    stims = pd.read_csv(stimuli_file)\n",
    "    if \"scale_id\" not in list(stims):\n",
    "        try:\n",
    "            stims[\"scale_id\"] = stims.Weaker + \"/\" + stims.Stronger\n",
    "        except:\n",
    "            stims[\"scale_id\"] = stims.weak_adj + \"/\" + stims.strong_adj\n",
    "\n",
    "    # Add surprisal results.\n",
    "    print(\"Adding strong scalemate surprisal results\")\n",
    "    strong_surp[\"strong\"] = strong_surp.scale_id.str.split('/').str[1]\n",
    "    strong_surp[\"is_strong_scalemate\"] = strong_surp.apply(\n",
    "        lambda r: r.content==r.strong+\".\" or r.content.split()[0]==r.strong or f\" {r.strong}\" in r.content, \n",
    "        axis=1\n",
    "    )\n",
    "    s = strong_surp[strong_surp.is_strong_scalemate].set_index(\"scale_id\")\n",
    "    if template is None:\n",
    "        surprisal_col_name = f\"surprisal_{model}\"\n",
    "    else:\n",
    "        surprisal_col_name = f\"surprisal_{model}_template{template}\"\n",
    "    stims[surprisal_col_name] = stims.apply(\n",
    "        lambda row: s.loc[row.scale_id].metric_value if row.scale_id in s.index else None, \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Standardize dependent variable name across datasets.\n",
    "    stims = stims.rename(columns={\n",
    "        \"SI percent (Exp 1)\": \"si_rate\",\n",
    "        \"SI_rate\": \"si_rate\",\n",
    "        \"si_nonneutral\": \"si_rate\"\n",
    "    })\n",
    "    \n",
    "    return stims, strong_surp, sentence_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9a339c-b582-432f-8231-15686e4cafe0",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b90760-a577-4f20-a264-097d4b02a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ronai & Xiang (2022)\n",
    "rx, rx_strong, rx_sents = process_model_outputs(\n",
    "    \"./model_results/rx22\", \n",
    "    \"./human_data/rx22.csv\"\n",
    ")\n",
    "rx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862df7d-acb6-4378-b553-008faa34a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pankratz & van Tiel (2021)\n",
    "pvt, pvt_strong, pvt_sents = process_model_outputs(\n",
    "    \"./model_results/pvt21\", \n",
    "    \"./human_data/pvt21.csv\"\n",
    ")\n",
    "pvt[\"si_rate\"] *= 100\n",
    "pvt[\"pos\"] = \"adj\" # all adjectival\n",
    "pvt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb10d5e-0e62-4585-9056-4dbac6e9433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gotzner et al. (2018)\n",
    "gz, gz_strong, gz_sents = process_model_outputs(\n",
    "    \"./model_results/g18\", \n",
    "    \"./human_data/g18.csv\"\n",
    ")\n",
    "gz[\"si_rate\"] *= 100\n",
    "gz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a98032b-b993-41e4-9f4b-c0658d104e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# van Tiel et al. (2016)\n",
    "vt1, vt_strong1, vt_sents1 = process_model_outputs(\n",
    "    \"./model_results/vt16/template1\", \"./human_data/vt16.csv\", template=1\n",
    ")\n",
    "vt2, vt_strong2, vt_sents2 = process_model_outputs(\n",
    "    \"./model_results/vt16/template2\", \"./human_data/vt16.csv\", template=2\n",
    ")\n",
    "vt3, vt_strong3, vt_sents3 = process_model_outputs(\n",
    "    \"./model_results/vt16/template3\", \"./human_data/vt16.csv\", template=3\n",
    ")\n",
    "vt = vt1.copy()\n",
    "metric = \"surprisal\"\n",
    "vt[f\"{metric}_gpt2_template2\"] = vt2[f\"{metric}_gpt2_template2\"]\n",
    "vt[f\"{metric}_gpt2_template3\"] = vt3[f\"{metric}_gpt2_template3\"]\n",
    "vt[f\"{metric}_gpt2\"] = vt.apply(\n",
    "    lambda r: np.mean([r[f\"{metric}_gpt2_template{template}\"] for template in [1,2,3]]),\n",
    "    axis=1\n",
    ")\n",
    "vt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22c47b-2cb0-4bc5-9e91-ea496563420f",
   "metadata": {},
   "source": [
    "# Bookkeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceef6eb-0f00-47a4-a9af-760f8697c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique_scales = len(set(\n",
    "    rx.dropna().scale_id.unique().tolist() + \n",
    "    pvt.dropna().scale_id.unique().tolist() + \n",
    "    gz.dropna().scale_id.unique().tolist() + \n",
    "    vt.dropna().scale_id.unique().tolist()\n",
    "))\n",
    "print(f\"{n_unique_scales} total unique scales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f3d914-b480-43c2-8774-383a0194b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\n",
    "    (\"Ronai & Xiang (2022)\", rx),\n",
    "    (\"Pankratz & van Tiel (2021)\", pvt),\n",
    "    (\"Gotzner et al. (2018)\", gz),\n",
    "    (\"van Tiel et al. (2016)\", vt)\n",
    "]\n",
    "\n",
    "for name, df in DATASETS:\n",
    "    print(name)\n",
    "    print(df.dropna().pos.value_counts())\n",
    "    print(\"Total unique scales:\", df.dropna().scale_id.nunique())\n",
    "    print(\"~\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a0a25-3040-49e6-a25f-84246f4b7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "UNIQUE_SCALES = defaultdict(list)\n",
    "for pos in [\"adj\", \"adv\", \"verb\"]:\n",
    "    for _, df in DATASETS:\n",
    "        scales = df[df.pos==pos].dropna().scale_id.tolist()\n",
    "        UNIQUE_SCALES[pos] += scales\n",
    "UNIQUE_SCALES = {pos: set(scales) for pos, scales in UNIQUE_SCALES.items()}\n",
    "for pos, scales in UNIQUE_SCALES.items():\n",
    "    print(pos, len(scales))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e514a26-3857-4b87-ab94-2c0134f2f858",
   "metadata": {},
   "source": [
    "# Main results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85dd2b0-f261-4e63-9de1-eba56db54b7f",
   "metadata": {},
   "source": [
    "## Figure 3a: String-based surprisal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb409a-c5d0-42d4-b204-c44c4288868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables for plotting.\n",
    "x = \"surprisal_gpt2\"\n",
    "metric = x.split(\"_\")[0]\n",
    "y = \"si_rate\"\n",
    "\n",
    "# Set up subplots.\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(DATASETS), sharey=True, sharex=False)\n",
    "\n",
    "# Iterate over datasets and axes.\n",
    "for dataset_idx, (dataset_name, df) in enumerate(DATASETS):\n",
    "    print(dataset_name)\n",
    "    ax, r, p = regplt(\n",
    "        df.dropna(), \n",
    "        x, \n",
    "        y, \n",
    "        ax=axes[dataset_idx], \n",
    "        color=SURPRISAL_COLOR, \n",
    "        marker=MARKERS[dataset_idx],\n",
    "        annot=False\n",
    "    )\n",
    "    ax.set_title(dataset_name, pad=26, size=16)\n",
    "    ax.text(\n",
    "        0.5, 1.07, f\"$r = {r:.3f}, p = {p:.3f}$\", color=\"dimgrey\",\n",
    "        size=14, transform=ax.transAxes, horizontalalignment='center', verticalalignment='center'\n",
    "    )\n",
    "    if dataset_idx == 0:\n",
    "        ax.set_ylabel(\"Human SI rate\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "fig.text(0.5, -0.1, \"Surprisal of strong scalemate\", ha='center', size=18)\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "fig.set_size_inches(13,3)\n",
    "render(f\"cross-scale_{metric}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2db23d6-e60b-4976-abab-ada2b63a4277",
   "metadata": {},
   "source": [
    "Footnote 9: Recompute results after removing outlier from Gotzner et al.'s (2018) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ba805-e0b3-4423-8c47-0c668ca30d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"si_rate\"\n",
    "x = \"surprisal_gpt2\"\n",
    "for dataset_idx, (dataset_name, df) in enumerate(DATASETS):\n",
    "    if dataset_name == \"Gotzner et al. (2018)\":\n",
    "        # Remove outliers\n",
    "        outliers = df.dropna()[(np.abs(stats.zscore(df.dropna()[x])) >= 3)]\n",
    "        print(outliers)\n",
    "        tmp = df.dropna()[(np.abs(stats.zscore(df.dropna()[x])) < 3)].copy()\n",
    "        r, p = stats.pearsonr(tmp[x], tmp[y])\n",
    "        print(f\"Without outliers: r={r}, p={p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e1123-d8a0-4855-8c62-ed9b8fc83316",
   "metadata": {},
   "source": [
    "## Figure 3b: Weighted average surprisal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49557daf-a96f-402e-9362-a1617563c1dd",
   "metadata": {},
   "source": [
    "Prep data: get distributions over full alternative set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154002b-0ea4-42cb-8db7-e54133750194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dists_ranks(strong, exclusions=[], top_k=None):\n",
    "    g = strong.groupby(\"scale_id\").apply(\n",
    "        lambda x: x.sort_values(by=\"metric_value\", ascending=True)\n",
    "    ).drop(\"scale_id\", axis=1).reset_index()\n",
    "    dists, ranks = [], []\n",
    "    for scale_id in sorted(g.scale_id.unique()):\n",
    "        strong_scalemate = scale_id.split(\"/\")[1]\n",
    "        if all(e != scale_id.split(\"/\")[0] for e in exclusions):\n",
    "            rows = g[g.scale_id==scale_id].reset_index()\n",
    "            # Get rank of strong scalemate.\n",
    "            surprisals = rows.metric_value\n",
    "            scalemates = rows.content.tolist()\n",
    "            try:\n",
    "                rank = next(\n",
    "                    (i for i in range(len(scalemates)) if scalemates[i] == strong_scalemate+\".\" or scalemates[i].split()[0] == strong_scalemate)\n",
    "                ) + 1\n",
    "                ranks.append(dict(\n",
    "                    scale_id=scale_id,\n",
    "                    rank=rank,\n",
    "                    surprisal=surprisals[rank-1]\n",
    "                ))\n",
    "            except:\n",
    "                print(\"skipping\", scale_id)\n",
    "                continue\n",
    "            \n",
    "            # Get scores for top k scalemates.\n",
    "            if top_k is not None:\n",
    "                iterrows = list(rows.iterrows())[:top_k]\n",
    "            else:\n",
    "                iterrows = list(rows.iterrows())\n",
    "            for i, row in iterrows:\n",
    "                surprisal = row.metric_value\n",
    "                dists.append(dict(\n",
    "                    scale_id=scale_id,\n",
    "                    rank=i+1,\n",
    "                    scalemate=row.content,\n",
    "                    surprisal=row.metric_value,\n",
    "                    prob=np.exp(-row.metric_value),\n",
    "                    is_strong_scalemate=(row.content==strong_scalemate+\".\" or row.content.split()[0]==strong_scalemate)\n",
    "                ))\n",
    "    \n",
    "    dists = pd.DataFrame(dists)\n",
    "    ranks = pd.DataFrame(ranks)\n",
    "    return dists, ranks\n",
    "\n",
    "def add_rank_data(ranks, orig, template=None):\n",
    "    if template is None:\n",
    "        col_name = \"strong_scalemate_rank_gpt2\"\n",
    "    else:\n",
    "        col_name = f\"strong_scalemate_rank_gpt2_template{template}\"\n",
    "                \n",
    "    for i, row in orig.iterrows():\n",
    "        if row.scale_id in ranks.scale_id.unique():\n",
    "            rank = ranks[ranks.scale_id==row.scale_id].squeeze()[\"rank\"]\n",
    "            orig.loc[i, col_name] = rank\n",
    "    orig[f\"log_{col_name}\"] = np.log(orig[col_name])\n",
    "    return orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74631d-670d-458e-ac1e-d08c5dc604b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data for Ronai & Xiang (2022).\n",
    "rx_dists, rx_ranks = get_dists_ranks(rx_strong)\n",
    "print(rx_ranks.head())\n",
    "rx = add_rank_data(rx_ranks, rx)\n",
    "\n",
    "# Prep data for Pankratz & van Tiel (2021).\n",
    "pvt_dists, pvt_ranks = get_dists_ranks(pvt_strong)\n",
    "print(pvt_ranks.head())\n",
    "pvt = add_rank_data(pvt_ranks, pvt)\n",
    "\n",
    "# Prep data for Gotzner et al. (2018)\n",
    "gz_dists, gz_ranks = get_dists_ranks(gz_strong)\n",
    "print(gz_ranks.head())\n",
    "gz = add_rank_data(gz_ranks, gz)\n",
    "\n",
    "# Prep data for van Tiel et al. (2016)\n",
    "vt_dists1, vt_ranks1 = get_dists_ranks(vt_strong1)\n",
    "vt_dists2, vt_ranks2 = get_dists_ranks(vt_strong2)\n",
    "vt_dists3, vt_ranks3 = get_dists_ranks(vt_strong3)\n",
    "vt = add_rank_data(vt_ranks1, vt, template=1)\n",
    "vt = add_rank_data(vt_ranks2, vt, template=2)\n",
    "vt = add_rank_data(vt_ranks3, vt, template=3)\n",
    "vt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0882ed79-be59-40f2-926b-9c1ab3203998",
   "metadata": {},
   "source": [
    "Prep word vectors to get similarity-based weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9176e-325c-4d48-be50-7ce1951d442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read word vectors. This may take a while (~1min).\n",
    "glove_file = \"glove.6B.300d.txt\"\n",
    "with open(glove_file, 'r') as f:\n",
    "    glove_vectors = {}\n",
    "    for line in f:\n",
    "        vals = line.rstrip().split(' ')\n",
    "        glove_vectors[vals[0]] = np.array([float(x) for x in vals[1:]]).reshape(1, -1)\n",
    "print(\"Successfully loaded GloVe vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3084f821-0164-46d1-975b-02965f95391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for getting cosine similarity between word vectors\n",
    "def get_sim(w1, w2, vectors):\n",
    "    try:\n",
    "        v1, v2 = vectors[w1], vectors[w2]\n",
    "        sim = cosine_similarity(v1, v2)\n",
    "        return sim[0][0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Helper function for getting similarity for top k scalemates and strong scalemate\n",
    "def get_sim_scalemates(dists, vectors, topk=None):\n",
    "    if topk is not None:\n",
    "        dists = dists[dists[\"rank\"]<=topk]\n",
    "    dists[\"cosine_sim_strong\"] = dists.apply(\n",
    "        lambda row: get_sim(row.scalemate, row.scale_id.split(\"/\")[1], vectors),\n",
    "        axis=1\n",
    "    )\n",
    "    return dists\n",
    "\n",
    "# Get weighted average surprisal over full alternative set\n",
    "def get_weighted_avg_surprisal(dists, vectors, **kwargs):\n",
    "    print(\"Getting similarity scores\")\n",
    "    dists = get_sim_scalemates(dists, vectors, **kwargs)\n",
    "    print(\"Computing weighted average surprisals\")\n",
    "    data = []\n",
    "    sims_data = []\n",
    "    for scale_id in dists.scale_id.unique():\n",
    "        d = dists[dists.scale_id==scale_id]\n",
    "        probs = d[~d.cosine_sim_strong.isna()].prob\n",
    "        sims = d[~d.cosine_sim_strong.isna()].cosine_sim_strong\n",
    "        sims_data.append(dict(scale_id=scale_id, sims=sims.tolist()))\n",
    "        weights = sims + 1 # translate from [-1, 1] to [0, 2] - avoid weirdness of negative weights\n",
    "        if sum(sims) != 0:\n",
    "            wavg_surp = -np.log(np.average(probs, weights=weights))\n",
    "            data.append(dict(\n",
    "                scale_id=scale_id,\n",
    "                weighted_avg_surprisal=wavg_surp\n",
    "            ))\n",
    "    return pd.DataFrame(data), pd.DataFrame(sims_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ce2cbe-34c4-47b5-9964-174ad77569bb",
   "metadata": {},
   "source": [
    "Computed weighted-average surprisal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b72b7e-21d4-4a97-9efe-71f8f8a2f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wavg(*args, **kwargs):\n",
    "    wavg, sims = get_weighted_avg_surprisal(*args, **kwargs)\n",
    "    wavg = wavg.set_index(\"scale_id\").weighted_avg_surprisal\n",
    "    return wavg, sims\n",
    "\n",
    "topk = None\n",
    "embs = glove_vectors \n",
    "all_sims = []\n",
    "\n",
    "print(\"Ronai & Xiang (2022)\")\n",
    "wavg, sims = get_wavg(rx_dists, embs, topk=topk)\n",
    "sims[\"dataset\"] = \"rx22\"\n",
    "all_sims.append(sims)\n",
    "for i, row in tqdm(rx.iterrows(), total=len(rx.index)):\n",
    "    rx.loc[i, \"weighted_avg_surprisal\"] = wavg.loc[row.scale_id] if row.scale_id in wavg else None\n",
    "    \n",
    "print(\"Pankratz & van Tiel (2021)\")\n",
    "wavg, sims = get_wavg(pvt_dists, embs, topk=topk)\n",
    "sims[\"dataset\"] = \"pvt21\"\n",
    "all_sims.append(sims)\n",
    "for i, row in tqdm(pvt.iterrows(), total=len(pvt.index)):\n",
    "    pvt.loc[i, \"weighted_avg_surprisal\"] = wavg.loc[row.scale_id] if row.scale_id in wavg else None\n",
    "\n",
    "print(\"Gotzner et al. (2018)\")\n",
    "wavg, sims = get_wavg(gz_dists, embs, topk=topk)\n",
    "sims[\"dataset\"] = \"gz18\"\n",
    "all_sims.append(sims)\n",
    "for i, row in tqdm(gz.iterrows(), total=len(gz.index)):\n",
    "    gz.loc[i, \"weighted_avg_surprisal\"] = wavg.loc[row.scale_id] if row.scale_id in wavg else None\n",
    "    \n",
    "print(\"van Tiel et al. (2016)\")\n",
    "wavg1, sims1 = get_wavg(vt_dists1, embs, topk=topk)\n",
    "wavg2, sims2 = get_wavg(vt_dists2, embs, topk=topk)\n",
    "wavg3, sims3 = get_wavg(vt_dists3, embs, topk=topk)\n",
    "sims[\"dataset\"] = \"vt16\"\n",
    "all_sims.append(sims)\n",
    "for i, row in tqdm(vt.iterrows(), total=len(vt.index)):\n",
    "    vals = [wavg.loc[row.scale_id] for wavg in [wavg1, wavg2, wavg3] if row.scale_id in wavg]\n",
    "    vt.loc[i, \"weighted_avg_surprisal\"] = np.mean(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8653a8aa-a0e6-476a-a4ba-bb3e84ff8489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables for plotting.\n",
    "x = \"weighted_avg_surprisal\"\n",
    "y = \"si_rate\"\n",
    "\n",
    "# Set up subplots.\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(DATASETS), sharey=True, sharex=False)\n",
    "\n",
    "# Iterate over datasets and axes.\n",
    "for dataset_idx, (dataset_name, df) in enumerate(DATASETS):\n",
    "    ax, r, p = regplt(\n",
    "        df.dropna(), \n",
    "        x, \n",
    "        y, \n",
    "        ax=axes[dataset_idx], \n",
    "        color=SURPRISAL_COLOR, \n",
    "        marker=MARKERS[dataset_idx],\n",
    "        annot=False\n",
    "    )\n",
    "    ax.set_title(dataset_name, pad=26, size=16)\n",
    "    p_str = f\"{p:.4f}\" if p < 0.001 else f\"{p:.3f}\"\n",
    "    ax.text(\n",
    "        0.5, 1.07, f\"$r = {r:.3f}, p = {p_str}$\", color=\"dimgrey\",\n",
    "        size=14, transform=ax.transAxes, horizontalalignment='center', verticalalignment='center'\n",
    "    )\n",
    "    if dataset_idx == 0:\n",
    "        ax.set_ylabel(\"Human SI rate\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "fig.text(0.5, -0.1, \"Weighted average surprisal\", ha='center', size=18)\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "fig.set_size_inches(13,3)\n",
    "render(f\"cross-scale_{x}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099188bc-f344-40fa-a76d-ef8a3814b511",
   "metadata": {},
   "source": [
    "## Table 4: Multivariate analysis & ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5325397-cc00-4d47-be0a-3017e937ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sig_code(p):\n",
    "    if p < 0.001:\n",
    "        return \"***\"\n",
    "    elif p < 0.01:\n",
    "        return \"**\"\n",
    "    elif p < 0.05:\n",
    "        return \"*\"\n",
    "    elif p < 0.1:\n",
    "        return \".\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def fit_reg_models(df):\n",
    "    # Initialize list of model results.\n",
    "    all_results = []\n",
    "    \n",
    "    # Two models: one with both surprisal predictors, and one with neither.\n",
    "    formula_main = \"si_rate ~ 1 + csurprisal + cweighted_avg_surprisal\"\n",
    "    formula_no_effects = \"si_rate ~ 1\"\n",
    "    m_main = smf.ols(formula_main, data=df).fit()\n",
    "    m_no_effects = smf.ols(formula_no_effects, data=df).fit()\n",
    "    \n",
    "    # Record results.\n",
    "    for i, m in enumerate([m_main, m_no_effects]):\n",
    "        coeffs = m.params.to_frame().reset_index().set_axis(['variable', 'coeff'], axis=1).set_index('variable')\n",
    "        pvals = m.pvalues.to_frame().reset_index().set_axis(['variable', 'pval'], axis=1).set_index('variable')\n",
    "        results = coeffs.join(pvals).reset_index()\n",
    "        # results = results[results.variable != \"Intercept\"]\n",
    "        results[\"sig\"] = results[\"pval\"] < 0.05\n",
    "        results[\"sig_code\"] = results[\"pval\"].apply(get_sig_code)\n",
    "        results[\"formula\"] = [formula_main, formula_no_effects][i]\n",
    "        all_results.append(results)\n",
    "    \n",
    "    # ANOVA\n",
    "    anova = sm.stats.anova_lm(m_no_effects, m_main, typ=1)\n",
    "    return anova, pd.concat(all_results)\n",
    "\n",
    "stat_dfs = []\n",
    "anova_dfs = []\n",
    "for (dataset_name, df) in DATASETS:\n",
    "    # Center the relevant variables.\n",
    "    s = df.copy()\n",
    "    s[\"csurprisal\"] = (s.surprisal_gpt2 - s.surprisal_gpt2.mean())\n",
    "    s[\"cweighted_avg_surprisal\"] = (s.weighted_avg_surprisal - s.weighted_avg_surprisal.mean())\n",
    "\n",
    "    # Fit models and perform ANOVA.\n",
    "    anova, res = fit_reg_models(s)\n",
    "    anova[\"dataset\"] = dataset_name\n",
    "    anova[\"sig\"] = anova[\"Pr(>F)\"] < 0.05\n",
    "    anova[\"sig_code\"] = anova[\"Pr(>F)\"].apply(get_sig_code)\n",
    "    res[\"dataset\"] = dataset_name\n",
    "    anova_dfs.append(anova)\n",
    "    stat_dfs.append(res)\n",
    "    \n",
    "stat_df = pd.concat(stat_dfs)\n",
    "anova_df = pd.concat(anova_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb822e8-bbda-4a55-b0d6-7d27e157703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b206beb9-42b9-48f8-abe8-94b11548e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134a1bd9-7b1c-491a-b1d7-9f14e33f4df8",
   "metadata": {},
   "source": [
    "## Figure 4: Model surprisal vs. human completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70eb070-8d6f-4545-b855-ed655eba30d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, r, p = regplt(\n",
    "    rx.dropna(), \n",
    "    \"surprisal_gpt2\", \n",
    "    \"Acessibility (Exp 2)\", \n",
    "    color=SURPRISAL_COLOR,\n",
    "    annot=False,\n",
    "    marker=MARKERS[0],\n",
    "    scatter_kws=dict(s=40)\n",
    ")\n",
    "ax.set_xlabel(\"Surprisal of strong scalemate\")\n",
    "ax.set_ylabel(\"\\\"Accessibility\\\" score\")\n",
    "ax.set_title(f\"Ronai & Xiang (2022)\", pad=26)\n",
    "ax.text(\n",
    "    0.5, 1.07, f\"$r = {r:.3f}, p = {p:.3f}$\", color=\"dimgrey\",\n",
    "    size=15, transform=ax.transAxes, horizontalalignment='center', verticalalignment='center'\n",
    ")\n",
    "plt.gcf().set_size_inches(2.837,3)\n",
    "render(\"accessibility_rx22.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187818fd-cd5b-424d-8c86-4ce0611ddb59",
   "metadata": {},
   "source": [
    "# Qualitative analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6cdc7c-37b4-4de4-abd3-d2b0caace83a",
   "metadata": {},
   "source": [
    "## Figure 5: top-ranked alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ae45b-4337-4988-a9df-4b478206da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "include = [\"big/enormous\", \"largely/totally\", \"hard/unsolvable\"] \n",
    "g = sns.catplot(\n",
    "    data=rx_dists[(rx_dists.scale_id.isin(include))&(rx_dists[\"rank\"]<=5)], \n",
    "    x=\"prob\", y=\"scalemate\", \n",
    "    col=\"scale_id\", kind=\"bar\",\n",
    "    col_order=include,\n",
    "    sharex=False, sharey=False,\n",
    "    height=3, aspect=1.5\n",
    ")\n",
    "g.set_axis_labels(\"P(alternative | context)\", \"Alternative\")\n",
    "axes = g.axes[0]\n",
    "for ax in axes:\n",
    "    ax.set_title(\"\")\n",
    "render(\"top_ranked_alts_rx22_notitles.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52432a3b-4b34-405e-a65c-4596774d4094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
