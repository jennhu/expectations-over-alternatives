{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3800369-910e-4063-b2f7-764b70565adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44a2cdb-274e-4140-a271-a5f1a55ade03",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\", font_scale=1.5, font=\"Liberation Sans\")\n",
    "MODEL = \"bert-base-uncased\"\n",
    "ALTERNATIVES = [\"each\", \"every\", \"few\", \"half\", \"much\", \"many\", \"most\", \"all\"]\n",
    "SURPRISAL_COLOR = \"steelblue\"\n",
    "HUMAN_MEASURE_LABEL = \"Human SI strength rating\"\n",
    "\n",
    "def render(file_name):\n",
    "    plt.savefig(f\"./figures/{file_name}\", dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"Rendered figure to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa3923-0bcb-488b-8f90-7d452bb831c2",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede804b-08e3-48d7-94d4-9f8e2b2c53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "human = pd.read_csv(\"./data/some-all/some_database.tsv\", sep=\"\\t\")\n",
    "human.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4f056d-0b1e-41f4-8054-efa90ffab342",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of participants:\", human.workerid.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e030c6-ce20-452a-a209-86e64bc0a770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_results(scale):\n",
    "    results = []\n",
    "    for strong in ALTERNATIVES:\n",
    "        df = pd.read_csv(f\"./data/{scale}/model_output/{MODEL}_{strong}.csv\")\n",
    "        df[\"model\"] = MODEL\n",
    "        df[\"strong\"] = strong\n",
    "        df[\"predicted_strong\"] = (df[\"predicted_token\"] == strong)\n",
    "        results.append(df)\n",
    "\n",
    "    df = pd.concat(results).rename(columns={\"Item_ID\": \"item_number\"})\n",
    "    df[\"prob_at_strong\"] = np.exp(-df[\"surprisal_at_strong\"])\n",
    "    return df\n",
    "\n",
    "model_df = load_model_results(\"some-all\")\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c68c7-15e4-415a-91c5-53e44e8e8b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.groupby([\"model\", \"strong\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c0713b-b7fd-404c-9771-a2666b43e700",
   "metadata": {},
   "source": [
    "## Combine model and human data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d960e3a-e541-42f8-8fd5-678dedb81df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which variables from the human experiment do we want to carry over?\n",
    "relevant_num_vars = [\"Rating\", \"StrengthSome\", \"SentenceLength\"]\n",
    "relevant_cat_vars = [\"Partitive\", \"Mention\", \"Subjecthood\", \"Modification\"]\n",
    "\n",
    "g = human.set_index(\"Item\")\n",
    "    \n",
    "# Add these variables to the model results.\n",
    "for v in relevant_num_vars:\n",
    "    model_df[v] = model_df.apply(\n",
    "        lambda row: g.loc[row.Item][v].mean() if row.Item in g.index else None,\n",
    "        axis=1\n",
    "    )\n",
    "for v in relevant_cat_vars:\n",
    "    model_df[v] = model_df.apply(\n",
    "        lambda row: g.loc[row.Item][v].values[0] if row.Item in g.index else None,\n",
    "        axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee2e17-b373-4f75-87e6-4b5ce0c59a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we aren't double-counting items\n",
    "model_df.groupby([\"model\", \"strong\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebd5c17-19e0-4784-91cb-a8510b3ee122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only care about surprisal for <some, all>.\n",
    "df_all = model_df[model_df.strong==\"all\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e812d42-3ff3-470a-98e2-adc8df4dfc70",
   "metadata": {},
   "source": [
    "# Figure 2a: String-based surprisal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd77a6b-4f0d-41ee-8488-7e6f39360b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotting variables.\n",
    "x = f\"surprisal_at_strong\"\n",
    "y = \"Rating\"\n",
    "\n",
    "# Plot line of best fit.\n",
    "ax = sns.regplot(\n",
    "    data=df_all.dropna(), x=x, y=y, \n",
    "    color=SURPRISAL_COLOR, marker=\"o\",\n",
    "    scatter_kws=dict(alpha=0.1)\n",
    ")\n",
    "r, p = stats.spearmanr(df_all.dropna()[x], df_all.dropna()[y])\n",
    "print(MODEL, f\"Spearman r={r:.3f}, p={p:.3e}\")\n",
    "r, p = stats.pearsonr(df_all.dropna()[x], df_all.dropna()[y])\n",
    "print(MODEL, f\"Pearson r={r:.3f}, p={p:.3e}\")\n",
    "\n",
    "\n",
    "# Add stats to title.\n",
    "if p < 0.0001:\n",
    "    p_str = \"p < 0.0001\"\n",
    "else:\n",
    "    p_str = f\"p={p:.3e}\"\n",
    "ax.set_title(f\"$r={r:.3f}, {p_str}$\", color=\"dimgrey\", size=16)\n",
    "\n",
    "# Set labels and size.\n",
    "ax.set_ylabel(HUMAN_MEASURE_LABEL)\n",
    "ax.set_xlabel(\"Surprisal of \\\"all\\\"\")\n",
    "ax.set_ylim(0.5,7.5)\n",
    "plt.gcf().set_size_inches(4,3.5)\n",
    "\n",
    "# Render and show plot.\n",
    "render(f\"{MODEL}_within-scale_surprisal.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b485448-b8ec-45f8-bc4b-8a97ccce4ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## NOTE: This plot is not included in the paper, but the stats are reported in Footnote 4.\n",
    "\n",
    "# Set plotting variables.\n",
    "x = f\"prob_at_strong\"\n",
    "y = \"Rating\"\n",
    "\n",
    "# Plot line of best fit.\n",
    "ax = sns.regplot(\n",
    "    data=df_all.dropna(), x=x, y=y, \n",
    "    color=SURPRISAL_COLOR, marker=\"o\",\n",
    "    scatter_kws=dict(alpha=0.1)\n",
    ")\n",
    "r, p = stats.spearmanr(df_all.dropna()[x], df_all.dropna()[y])\n",
    "print(MODEL, f\"Spearman r={r:.3f}, p={p:.3e}\")\n",
    "r, p = stats.pearsonr(df_all.dropna()[x], df_all.dropna()[y])\n",
    "print(MODEL, f\"Pearson r={r:.3f}, p={p:.3e}\")\n",
    "\n",
    "\n",
    "# Add stats to title.\n",
    "if p < 0.0001:\n",
    "    p_str = \"p < 0.0001\"\n",
    "else:\n",
    "    p_str = f\"p={p:.3e}\"\n",
    "ax.set_title(f\"$r={r:.3f}, {p_str}$\", color=\"dimgrey\", size=16)\n",
    "\n",
    "# Set labels and size.\n",
    "ax.set_ylabel(HUMAN_MEASURE_LABEL)\n",
    "ax.set_xlabel(\"Probability of \\\"all\\\"\")\n",
    "plt.gcf().set_size_inches(4,3.5)\n",
    "\n",
    "# Show plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c331f72c-8660-4a74-9355-43547621c391",
   "metadata": {},
   "source": [
    "# Figure 2b: Weighted average surprisal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de40f8-214e-4391-aec7-e0c818de2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read word vectors.\n",
    "glove_file = \"glove.6B.300d.txt\"\n",
    "with open(glove_file, 'r') as f:\n",
    "    glove_vectors = {}\n",
    "    for line in f:\n",
    "        vals = line.rstrip().split(' ')\n",
    "        glove_vectors[vals[0]] = np.array([float(x) for x in vals[1:]]).reshape(1, -1)\n",
    "print(\"Successfully loaded GloVe vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76751165-b4b3-4cee-ad63-00011e12af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for getting cosine similarity between word vectors\n",
    "def get_sim(w1, w2, vectors):\n",
    "    try:\n",
    "        v1, v2 = vectors[w1], vectors[w2]\n",
    "        sim = cosine_similarity(v1, v2)\n",
    "        return sim[0][0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Helper function for getting similarity for top k scalemates and strong scalemate\n",
    "def get_sim_scalemates(dists, vectors, topk=None):\n",
    "    if topk is not None:\n",
    "        dists = dists[dists[\"rank\"]<=topk]\n",
    "    dists[\"cosine_sim_strong\"] = dists.apply(\n",
    "        lambda row: get_sim(row.scalemate, \"all\", vectors),\n",
    "        axis=1\n",
    "    )\n",
    "    return dists\n",
    "\n",
    "# Get weighted average surprisal over full alternative set\n",
    "def get_weighted_avg_surprisal(dists, vectors, **kwargs):\n",
    "    print(\"Getting similarity scores\")\n",
    "    dists = get_sim_scalemates(dists, vectors, **kwargs)\n",
    "    print(\"Computing weighted average surprisals\")\n",
    "    data = []\n",
    "    sims_data = []\n",
    "    for item in dists[\"item\"].unique():\n",
    "        d = dists[dists[\"item\"]==item]\n",
    "        probs = d[~d.cosine_sim_strong.isna()].prob\n",
    "        sims = d[~d.cosine_sim_strong.isna()].cosine_sim_strong\n",
    "        sims_data.append(dict(item=item, sims=sims.tolist()))\n",
    "        weights = sims + 1 # translate from [-1, 1] to [0, 2] - avoid weirdness of negative weights\n",
    "        if sum(sims) != 0:\n",
    "            wavg_surp = -np.log(np.average(probs, weights=weights))\n",
    "            data.append(dict(\n",
    "                item=item,\n",
    "                weighted_avg_surprisal=wavg_surp\n",
    "            ))\n",
    "    return pd.DataFrame(data), pd.DataFrame(sims_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c0ecea-1578-4dc0-afd4-207781655f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdist = model_df.set_index([\"Item\", \"strong\"]).sort_index()\n",
    "dists = []\n",
    "for (item, strong), row in mdist.iterrows():\n",
    "    dists.append(dict(\n",
    "        scalemate=strong,\n",
    "        item=item,\n",
    "        surprisal=row.surprisal_at_strong,\n",
    "        prob=row.prob_at_strong,\n",
    "        is_strong_scalemate=(strong==\"all\")\n",
    "    ))\n",
    "dists = pd.DataFrame(dists).sort_values(by=[\"item\", \"scalemate\"])\n",
    "dists.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493f96f2-4e5e-4fb8-ae57-3aa00cc214d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wavg(*args, **kwargs):\n",
    "    wavg, sims = get_weighted_avg_surprisal(*args, **kwargs)\n",
    "    wavg = wavg.set_index(\"item\").weighted_avg_surprisal\n",
    "    return wavg, sims\n",
    "\n",
    "topk = None\n",
    "embs = glove_vectors \n",
    "\n",
    "wavg, sims = get_wavg(dists, embs, topk=topk)\n",
    "for i, row in tqdm(df_all.iterrows(), total=len(df_all.index)):\n",
    "    df_all.loc[i, \"weighted_avg_surprisal\"] = wavg.loc[row.Item] if row.Item in wavg else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75467fe8-ab75-4f2d-b007-88c491ffe50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotting variables.\n",
    "x = f\"weighted_avg_surprisal\"\n",
    "y = \"Rating\"\n",
    "\n",
    "# Plot line of best fit.\n",
    "ax = sns.regplot(\n",
    "    data=df_all.dropna(), x=x, y=y, \n",
    "    color=SURPRISAL_COLOR, marker=\"o\",\n",
    "    scatter_kws=dict(alpha=0.1)\n",
    ")\n",
    "r, p = stats.pearsonr(df_all.dropna()[x], df_all.dropna()[y])\n",
    "print(MODEL, f\"Pearson r={r:.3f}, p={p:.3e}\")\n",
    "\n",
    "# Add stats to title.\n",
    "if p < 0.0001:\n",
    "    p_str = \"p < 0.0001\"\n",
    "else:\n",
    "    p_str = f\"p={p:.3e}\"\n",
    "ax.set_title(f\"$r={r:.3f}, {p_str}$\", color=\"dimgrey\", size=16)\n",
    "\n",
    "# Set labels and size.\n",
    "ax.set_ylabel(HUMAN_MEASURE_LABEL)\n",
    "ax.set_xlabel(\"Weighted average surprisal\")\n",
    "plt.gcf().set_size_inches(4,3.5)\n",
    "ax.set_ylim(0.5,7.5)\n",
    "\n",
    "# Render and show plot.\n",
    "render(f\"{MODEL}_within-scale_weighted-avg-surprisal.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c11814f-0904-48aa-aaee-c26d6b60328a",
   "metadata": {},
   "source": [
    "# Table 2: Multivariate analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f19f52-8076-4b5a-9c10-9026884347a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sig_code(p):\n",
    "    if p < 0.001:\n",
    "        return \"***\"\n",
    "    elif p < 0.01:\n",
    "        return \"**\"\n",
    "    elif p < 0.05:\n",
    "        return \"*\"\n",
    "    elif p < 0.1:\n",
    "        return \".\"\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "def get_sig_code_num(p):\n",
    "    if p < 0.0001:\n",
    "        return \"< 0.0001\"\n",
    "    elif p < 0.001:\n",
    "        return \"< 0.001\"\n",
    "    elif p < 0.01:\n",
    "        return \"< 0.01\"\n",
    "    elif p < 0.05:\n",
    "        return \"< 0.05\"\n",
    "    elif p < 0.1:\n",
    "        return \"< 0.1\"\n",
    "    else:\n",
    "        return p\n",
    "\n",
    "def fit_reg_models(df):\n",
    "    all_results = []\n",
    "    formula = \"Rating ~ cPartitive + cStrengthSome + cRedMention + cSubjecthood + cModification + cSentenceLengthLog + csurprisal_at_strong + cweighted_avg_surprisal\"\n",
    "    m = smf.ols(formula, data=df).fit()\n",
    "    # print(m.summary())\n",
    "    coeffs = m.params.to_frame().reset_index().set_axis(['variable', 'coeff'], axis=1).set_index('variable')\n",
    "    pvals = m.pvalues.to_frame().reset_index().set_axis(['variable', 'pval'], axis=1).set_index('variable')\n",
    "    results = coeffs.join(pvals).reset_index()\n",
    "    results = results[results.variable != \"Intercept\"]\n",
    "    results[\"sig\"] = results[\"pval\"] < 0.05\n",
    "    results[\"sig_code_num\"] = results[\"pval\"].apply(get_sig_code_num)\n",
    "    results[\"sig_code\"] = results[\"pval\"].apply(get_sig_code)\n",
    "    all_results.append(results)\n",
    "    return pd.concat(all_results)\n",
    "\n",
    "s = df_all.copy()\n",
    "s[\"Partitive\"] = s.Partitive.map({\"yes\": 2, \"no\": 1})\n",
    "s[\"RedMention\"] = s.Mention.map({\"new\": 1, \"med\": 2, \"old\": 2})\n",
    "s[\"Modification\"] = s.Modification.map({\"modified\": 1, \"unmodified\": 2})\n",
    "s[\"Subjecthood\"] = s.Subjecthood.map({\"subject\": 2, \"other\": 1})\n",
    "s[\"SentenceLengthLog\"] = np.log(s.SentenceLength)\n",
    "\n",
    "# Center everything\n",
    "for c in [\"Partitive\", \"StrengthSome\", \"RedMention\", \"Subjecthood\", \"Modification\", \"SentenceLengthLog\", \n",
    "          \"surprisal_at_strong\", \"weighted_avg_surprisal\"]:\n",
    "    s[\"c\"+c] = s[c] - s[c].mean()\n",
    "\n",
    "stat_df = fit_reg_models(s)\n",
    "stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037578ab-867d-4c08-bf52-9fa921403398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
